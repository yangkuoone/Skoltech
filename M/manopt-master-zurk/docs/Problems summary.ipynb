{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems summary\n",
    "\n",
    "Main research fields:\n",
    "* Manifold optimization\n",
    "* Matrix Factorization\n",
    "\n",
    "The main application tasks:\n",
    "* Community detection\n",
    "* Computer tomography\n",
    "\n",
    "Here we have list of all ideas, which came to a head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifold optimization\n",
    "\n",
    "* Use it in Matrix Factorization tasks (Community detection in particular). Find out if it is helpful.\n",
    "* Try to solve rank selection problem in Matrix Factorization task.\n",
    "    * Approach 1. So, We have variety( $\\mathrm{rank}(A) < k$) optimization task. Research this approach.\n",
    "    * Find other approaches\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "\n",
    "* Logistic matrix factorization using Riemannian optimization\n",
    "    * [Oseledets project](http://oseledets.github.io/projects/#logistic-matrix-factorization-using-riemannian-optimization)\n",
    "    * Use Riemannian optimization in BigClam method (also logistic matrix factorization).\n",
    "        * Try to build scalable method (like coordinate decent)\n",
    "* Use Matrix Factorization approach in Computer tomography task\n",
    "    * Proof of concept. Find out applicability, benefits, problems. Consider different models and data examples.\n",
    "    * Add low-rank assumption to modern CT approaches.\n",
    "* Something about sensor positioning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riemannian 1-bit matrix completion and factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let our data be an adjancy matrix $A$ of a non-directed graph with $n$ vertices.\n",
    "\n",
    "\n",
    "* Introduce $M_{uv}$ - the value determining the probability of an edge between $u, v$.\n",
    "$$p(u,v) = 1 - \\exp( - M_{uv}),$$\n",
    "where $M$ is a symmetric matrix $M = M^T$.\n",
    "\n",
    "* We can write the likelihood of our data:\n",
    "$$\n",
    "    l(M) = \\sum_{(u,v)\\in E} \\log(1 - \\exp(- M_{uv})) - \\sum_{(u,v) \\notin E} M_{uv} \\rightarrow \\max_{M_{uv} \\ge 0, M = M^T}.\n",
    "$$\n",
    "\n",
    "* In order to proceed and make the estimation problem feasible we need to impose certain restrictions on matrix $M_{uv}$. One possible approach is to assume that matrix $M$ is low rank: $rank{M} \\le k$ with $k << n$. The respective optimization problem is\n",
    "$$\n",
    "    l(M) = \\sum_{(u,v)\\in E} \\log(1 - \\exp(- M_{uv})) - \\sum_{(u,v) \\notin E} M_{uv} \\rightarrow \\max_{M_{uv} \\ge 0, M = M^T, rank{M} \\le k}.\n",
    "$$\n",
    "\n",
    "* Ideally, we would like to solve directly this problem, but the alternative can be in considering fixed-rank situation $rank{M} = k$ leading to the problem\n",
    "$$\n",
    "    l(M) = \\sum_{(u,v)\\in E} \\log(1 - \\exp(- M_{uv})) - \\sum_{(u,v) \\notin E} M_{uv} \\rightarrow \\max_{M_{uv} \\ge 0, M = M^T, rank{M} = k},\n",
    "$$\n",
    "which is an optimization on the Riemannian manifold.\n",
    "\n",
    "* Afterwards we can decompose the solution as a product: $ M = F F^T$, where $F \\in \\mathbb{R}^{n \\times k}$ and consider rows of $F$ as community membership weights.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1) What are peculiarities of the manifold $rank M = k$ under additional constraints  $M_{uv} \\ge 0$ and $M = M^T$?\n",
    "\n",
    "2) What is the complexity of usual Riemannian optimization methods? Can we make them more scalable?\n",
    "\n",
    "3) What we can say about decomposition $M = F F^T$ in case when $rank{M} = k$, $M_{uv} \\ge 0$ and $F \\in \\mathbb{R}^{n \\times k}$? Can we make $F_{uv} \\ge 0$?\n",
    "\n",
    "4) This model is also suitable for matrix completion if we consider general $M \\in \\mathbb{R}^{n \\times m}$, $M_{uv} \\ge 0$ and we observe certain binary outcomes $a_{uv} \\in \\{0, 1\\}$ for some subset of pairs $(u, v) \\in S \\subseteq \\{1, \\dots, n\\} \\times \\{1, \\dots, m\\}$.\n",
    "\n",
    "5) We can consider some other variants of imposing structure on $M$:\n",
    "\n",
    "- sparse matrix;\n",
    "- matrix generated from graphon;\n",
    "- Eucledian distance matrix;\n",
    "- ... ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigCLAM approach\n",
    "The direct alternative is to model rank $k$ matrix as a product of $n \\times k$ matrices: $M = F F^T$, where $F \\in \\mathbb{R}^{n \\times k}$. This leads to the following optimization problem:\n",
    "\n",
    "$$\n",
    "    l(F) = \\sum_{(u,v)\\in E} \\log(1 - \\exp( - F_{u} F_{v}^T)) - \\sum_{(u,v) \\notin E} F_u F_v^T \\rightarrow \\max_{F\\ge0}.\n",
    "$$\n",
    "\t\n",
    "This problem allows quite nice block coordinate descent algorithm:\n",
    "$$\n",
    "    \\nabla l(F_u) = \\sum_{v \\in \\mathcal{N}(u)} F_u \\dfrac{\\exp(-F_u F_v^T)}{1-\\exp(-F_u F_v^T)} - \\sum_{v \\notin \\mathcal{N}(u)} F_v^T.\n",
    "$$\n",
    "\n",
    "Let's not that\n",
    "$$\n",
    "    \\sum_{v \\notin \\mathcal{N}(u)} F_v^T = \\sum_v{F_v} - F_u - \\sum_{v\\in \\mathcal{N}(u)} F_v.\n",
    "$$ \n",
    "\t\n",
    "Thus, complexity of one iteration is just $O(\\mathcal{N}(u))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question about BigCLAM\n",
    "\n",
    "1) Is such a direct approach more efficient? The optimization problem is not nice any more.\n",
    "\n",
    "2) Can we get all symmetric matrices $M$ with $rank{M} = k$ and $M_{uv} \\ge 0$ via modelling over $F F^T$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical properties\n",
    "\n",
    "1) There is a result in (Davenport, 2012) saying that with high probability $\\frac{1}{d^2} \\|\\hat{M} - M\\|_F^2 \\leq C \\sqrt{\\frac{kd}{m}}$, where $m$ is a number of observed entries. The result is proved for trace-norm regularization algorithm.\n",
    "\n",
    "2) There some other result (Bhashkar, 2015) even improving this up to $O(1 / m)$ considering the exact low-rank constraint and some barrier method for optimization.\n",
    "\n",
    "3) There are couple of papers (Wei, 2015, 2016) proving some properties of Riemannian optimization for low-rank matrix recovery. Notes:\n",
    "- they are more on optimization point of view, i.e. no noise and exact recovery.\n",
    "- they consider only general Eucledian loss.\n",
    "\n",
    "4) Question: can we do something for logistic matrix completion?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
